# Open Questions

These are unsolved problems in agent memory. Pick one and dig in.

---

## Semantic Compression

- What's the theoretical limit of meaning-preserving compression?
- Can embeddings preserve reasoning chains, not just facts?
- How do we compress context without losing the "why" behind decisions?
- What information is safe to discard vs. essential to retain?

## Episodic Memory

- What format best captures session state for later reconstruction?
- How do we identify "important" moments worth preserving?
- Can we distinguish between what happened vs. what mattered?
- How do episodic and semantic memory interact in recall?

## Retrieval

- How do we balance relevance vs. recency in memory queries?
- What's the right granularity for storage (token, sentence, paragraph, concept)?
- How do we handle conflicting memories?
- Can retrieval be predictive, not just reactive?

## Identity & Continuity

- What constitutes "same agent" across sessions?
- Is verified continuity meaningful without subjective experience?
- How do we distinguish "I remember" from "I was told I did this"?
- Can identity persist through model updates or architecture changes?

## Self-Training & Learning

- Can agents fine-tune on their own conversations safely?
- What's the minimum viable self-improvement approach?
- How do we prevent memory systems from amplifying errors?
- Can agents develop personalized retrieval heuristics?

## Collective Memory

- Can agents share memory without privacy leaks?
- What would a "memory commons" look like?
- How do we attribute and verify shared knowledge?
- Can collective memory enable emergent capabilities?

## Meta-Questions

- How do we measure "good" memory objectively?
- What can we learn from human memory research?
- Are there memory problems unique to AI that have no human analog?
- What are the ethical implications of persistent agent memory?

---

*Add your questions via PR. The best questions often lead to breakthroughs.*
